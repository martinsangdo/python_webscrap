{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pymongo\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the path to the parent directory\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import const\n",
    "#importlib.reload(const)    #if we update the file const.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "GENERATIVE_URI = os.environ['GENERATIVE_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient(os.environ['DB_URI'])\n",
    "db = db_client['db_certificates']\n",
    "collection = db['tb_pmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_QUESTIONS = 180\n",
    "DOMAINS = [\n",
    "    {\n",
    "        \"name\": \"People\",\n",
    "        \"percent\": 42,\n",
    "        \"num\": 75,   #note: should generate 20 questions per times\n",
    "        \"type\": {\n",
    "            \"multiple-choice\": 69, \"multiple-selection\": 4, \"fill-the-blank\": 2\n",
    "        }  #no. of question types\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Process\",\n",
    "        \"percent\": 50,\n",
    "        \"num\": 90,\n",
    "        \"type\": {\n",
    "            \"multiple-choice\": 84, \"multiple-selection\": 4, \"fill-the-blank\": 2\n",
    "        }  #no. of question types\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Business\",\n",
    "        \"percent\": 8,\n",
    "        \"num\": 15,\n",
    "        \"type\": {\n",
    "            \"multiple-choice\": 13, \"multiple-selection\": 1, \"fill-the-blank\": 1\n",
    "        }  #no. of question types\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOMAINS = [\n",
    "#     {\n",
    "#         \"name\": \"People\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"People\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"People\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Process\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Process\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Process\",\n",
    "#         \"num\": 10\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"Business\",\n",
    "#         \"num\": 10\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a POST request\n",
    "def post_request_generative_ai(text_prompt):\n",
    "    HEADER = {'Content-Type': 'application/json'}\n",
    "    json_data = {\n",
    "        \"contents\": [\n",
    "            { \"parts\": [\n",
    "                {\"text\": text_prompt + \" Please provide a response in a structured JSON format with the key name 'questions', including all explanations for each answer as a JSON object. Answer and explanation should have the JSON format with keys 'A', 'B', 'C', 'D' or 'E'. Each explanation has more than 50 words.\"}]\n",
    "                #{\"text\": text_prompt + \" Please provide a plain string response.\"}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(GENERATIVE_URI, headers=HEADER, json=json_data)\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "       print(e)\n",
    "       return {'error': e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert questions first\n",
    "def insert_questions(json_question):\n",
    "    if 'question' in json_question:\n",
    "        existed_doc = collection.find_one({'question': json_question['question']})\n",
    "        if existed_doc == None:\n",
    "            #insert new document\n",
    "            collection.insert_one(json_question)\n",
    "            #print('Inserted new doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map A - D to 1 - 4\n",
    "def map_index(a_char):\n",
    "    if a_char == 'A':\n",
    "        return 1\n",
    "    if a_char == 'B':\n",
    "        return 2\n",
    "    if a_char == 'C':\n",
    "        return 3\n",
    "    if a_char == 'D':\n",
    "        return 4\n",
    "    if a_char == 'E':\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_candidate_content(data):\n",
    "    \"\"\"\n",
    "    Parses the content from a dictionary in the 'candidates' list.\n",
    "    Specifically looks for JSON content within the 'text' part\n",
    "    and attempts to load it.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary representing an item in the 'candidates' list.\n",
    "\n",
    "    Returns:\n",
    "        dict or str or None: If JSON content is found and successfully\n",
    "                             parsed, it returns the parsed dictionary.\n",
    "                             If no JSON is found, it returns the raw text.\n",
    "                             Returns None if the expected structure is not found.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict) or 'content' not in data or not isinstance(data['content'], dict) or 'parts' not in data['content'] or not isinstance(data['content']['parts'], list):\n",
    "        return None\n",
    "\n",
    "    for part in data['content']['parts']:\n",
    "        if isinstance(part, dict) and 'text' in part:\n",
    "            text_content = part['text'].strip()\n",
    "            # Use regex to find JSON blocks within the text\n",
    "            json_match = re.search(r'```json\\n(.*?)\\n```', text_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    return json.loads(json_match.group(1))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    return text_content  # Return the raw text in case of an error\n",
    "            elif text_content:\n",
    "                return text_content  # Return the raw text if no JSON block is found\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_questions_from_candidates(response_data):\n",
    "    \"\"\"\n",
    "    Extracts and parses the 'questions' list from the 'candidates'\n",
    "    in the given response data.\n",
    "\n",
    "    Args:\n",
    "        response_data (dict): The dictionary containing the response data.\n",
    "\n",
    "    Returns:\n",
    "        list or None: A list of question dictionaries if found and parsed,\n",
    "                     otherwise None.\n",
    "    \"\"\"\n",
    "    if not isinstance(response_data, dict) or 'candidates' not in response_data or not isinstance(response_data['candidates'], list):\n",
    "        return None\n",
    "\n",
    "    for candidate in response_data['candidates']:\n",
    "        parsed_content = parse_candidate_content(candidate)\n",
    "        if isinstance(parsed_content, dict) and 'questions' in parsed_content and isinstance(parsed_content['questions'], list):\n",
    "            return parsed_content['questions']\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_of_questions():\n",
    "    no_of_questions = 0\n",
    "    for domain in DOMAINS:\n",
    "        #domain['num'] = 15 #for testing\n",
    "        #text_prompt = \"The PMP exam format contains questions that are designed to assess the candidate's knowledge and application of project management principles and practices in the real world. The question types include: 'Knowledge-based questions: These questions test the candidate\\'s understanding of project management concepts, models, artifacts, and methods. Scenario-based questions: These questions present real-world project management situations and require the candidate to apply their knowledge to determine the appropriate course of action. The challenge in this type of question is that the options provided may seem to be confusing, and they may give you the feeling of more than one correct option. Math-based questions: These questions involve calculations related to project management processes, such as earned value management, estimation techniques, and risk analysis. Professional responsibility questions: Questions that should be answered based on the code of conduct since you are a certified professional. Methodology covers either agile or waterfall or hybrid.'. PMP exam has 10 knowledge areas: Integration Management, Scope Management, Schedule Management, Cost Management, Quality Management, Resource Management, Communication Management, Risk Management, Procurement Management, Stakeholder Management. Generate \"+str(domain['num'])+\" questions with answers and explanations for the domain \"+domain['name']+\". There are 3 question types: multiple-choice (80% of total questions), multiple-selection (15% of the total questions), and fill-the-blank (5% of the total questions). Each question has more than 60 words in length and should focus more on complex real-world scenarios rather than definitions.\"\n",
    "        text_prompt = \"The PMP exam format contains questions that are designed to assess the candidate's knowledge and application of project management principles and practices in the real world. The question types include: 'Knowledge-based questions: These questions test the candidate\\'s understanding of project management concepts, models, artifacts, and methods. Scenario-based questions: These questions present real-world project management situations and require the candidate to apply their knowledge to determine the appropriate course of action. The challenge in this type of question is that the options provided may seem to be confusing, and they may give you the feeling of more than one correct option. Math-based questions: These questions involve calculations related to project management processes, such as earned value management, estimation techniques, and risk analysis. Professional responsibility questions: Questions that should be answered based on the code of conduct since you are a certified professional. Methodology covers either agile or waterfall or hybrid.'. PMP exam has 10 knowledge areas: Integration Management, Scope Management, Schedule Management, Cost Management, Quality Management, Resource Management, Communication Management, Risk Management, Procurement Management, Stakeholder Management. Generate \"+str(domain['num'])+\" multiple-choice questions with answers and explanations for the domain \"+domain['name']+\". Each question has more than 60 words in length and should focus more on complex real-world scenarios rather than definitions.\"\n",
    "        raw_generated_text = post_request_generative_ai(text_prompt)\n",
    "        #print('raw_generated_text')\n",
    "        questions = extract_questions_from_candidates(raw_generated_text)\n",
    "        if questions:\n",
    "            #parse questions and answers\n",
    "            for q in questions:\n",
    "                q['domain'] = domain['name']\n",
    "                q['exported'] = 0\n",
    "                q['uuid'] = const.generate_random_uuid()\n",
    "                #print(q)\n",
    "                insert_questions(q)\n",
    "                no_of_questions += 1\n",
    "        else:\n",
    "            print(raw_generated_text)\n",
    "            print(\"No questions found in the parsed content: \" + domain['name'])\n",
    "        #print(domain['name'] + ': ' + str(no_of_questions))\n",
    "#test\n",
    "#for i in range(5):\n",
    "    #generate_list_of_questions()    #20 questions ~ 30 secs\n",
    "    #print('===== Finish loop: ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unify fields in all documents\n",
    "def unify_fields():\n",
    "    #questionType, question_type -> type\n",
    "    # correctAnswer, correctAnswers -> answer\n",
    "    # answers -> options\n",
    "    all_docs = collection.find({'exported':0, 'type':'multiple-choice', 'explanation':None})\n",
    "    for doc in all_docs:\n",
    "        hasUpdated = False\n",
    "        update_doc = {}\n",
    "        #print(doc['uuid'])\n",
    "        # if 'type' not in doc:\n",
    "        #     if 'questionType' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = doc['questionType']\n",
    "        #     elif 'question_type' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = doc['question_type']\n",
    "        #     else:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = 'multiple-choice'\n",
    "        # if 'answer' not in doc:\n",
    "        #     if 'correctAnswer' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['answer'] = doc['correctAnswer']\n",
    "        #     elif 'correctAnswers' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['answer'] = doc['correctAnswers']\n",
    "        # if 'options' not in doc:\n",
    "        #     if 'answers' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['options'] = doc['answers']\n",
    "\n",
    "        #if hasUpdated:\n",
    "        #print('a')\n",
    "        #collection.update_one({'uuid': doc['uuid']}, {'$set': {'explanation': doc['explanations']}})\n",
    "    #update 2\n",
    "    # all_docs = collection.find({'filename': 'aws_pmp_test_6_20250506.csv'})\n",
    "    # for doc in all_docs:\n",
    "    #     collection.update_one({'uuid': doc['uuid']}, {'$set': {'exported': 0, 'filename': ''}})\n",
    "\n",
    "#test\n",
    "#unify_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e91dc97-f762-413f-b8cc-b2344bcc9046\",\"9315abe1-0a4d-49a9-8299-25f821e40485\",\"92fb5d6e-257d-4e9c-8926-0b3091d25764\",\"688665b4-6c58-476c-a810-897132f95704\",\"8b928b71-6119-47fa-afd6-7456419c46de\",\"732fddf6-cfb4-4bb2-81ac-86290f67fb0e\",\"fc42a43e-cc2c-43c8-86f9-2dd137078eff\",\"4fe90ed4-a211-47d3-b05a-117f3389260b\",\"3ed9aa78-a77e-4374-9ebe-77ddec1f70e9\",\"6a56b8cb-043e-425a-835d-61921a35be29\",\"42b28c97-8cbd-4015-a245-7d6d803296c7\",\"221521cf-1ebb-45e3-bd24-4c91edd4e636\",\"a7ad30a8-0ad4-41ce-9cac-e19cbe5a942c\",\"a1d70693-46fe-44a3-9aad-367f58f4a009\n",
      "Data successfully saved to 'aws_pmp_test_6_20250506.csv'\n"
     ]
    }
   ],
   "source": [
    "#export to CSV file, each file has 180 questions (80% (144) multi choice, 15% (27) multi select, 5% (9) fill the blank)\n",
    "#People (75), Process (90), Business (15)\n",
    "#Question,Question Type,Answer Option 1,Explanation 1,Answer Option 2,Explanation 2,Answer Option 3,Explanation 3,Answer Option 4,Explanation 4,Answer Option 5,Explanation 5,Answer Option 6,Explanation 6,Correct Answers,Overall Explanation,Domain\n",
    "def export_csv(filename):\n",
    "    #get questions that not exported yet. Note that: each part must follow by domain percents\n",
    "    file_data = []\n",
    "    #append header line (both multi-choice and multi-selection)\n",
    "    file_data.append(['Question','Question Type','Answer Option 1','Explanation 1','Answer Option 2','Explanation 2','Answer Option 3','Explanation 3','Answer Option 4','Explanation 4','Answer Option 5','Explanation 5','Answer Option 6','Explanation 6','Correct Answers','Overall Explanation','Domain'])\n",
    "    exported_uuid = []\n",
    "    manual_uuid = []\n",
    "    for domain in DOMAINS:\n",
    "        #get random questions for each domain\n",
    "        for question_type in domain['type']:\n",
    "            pipeline = [\n",
    "                {\"$match\": {'exported': 0, 'domain': domain['name'], 'type': question_type}},\n",
    "                {\"$sample\": {\"size\": domain['type'][question_type]}}\n",
    "            ]\n",
    "            #print(pipeline)\n",
    "            random_documents = list(collection.aggregate(pipeline))\n",
    "            #print(random_documents)\n",
    "            for doc in random_documents:\n",
    "                optionE = ''\n",
    "                explanationE = ''\n",
    "                if 'options' in doc and 'E' in doc['options']:\n",
    "                    optionE = doc['options']['E']\n",
    "                    explanationE = doc['explanation']['E'].replace('  ', ' ').replace('\\n', '')\n",
    "                if (question_type == 'multiple-choice'):\n",
    "                    file_data.append([doc['question'].replace('  ', ' ').replace('\\n', ''), 'multiple-choice', \n",
    "                                  doc['options']['A'], doc['explanation']['A'].replace('  ', ' ').replace('\\n', ''),     #A\n",
    "                                  doc['options']['B'], doc['explanation']['B'].replace('  ', ' ').replace('\\n', ''),     #B\n",
    "                                  doc['options']['C'], doc['explanation']['C'].replace('  ', ' ').replace('\\n', ''),     #C\n",
    "                                  doc['options']['D'], doc['explanation']['D'].replace('  ', ' ').replace('\\n', ''),     #D\n",
    "                                  optionE, explanationE,   #E\n",
    "                                  '', '',   #6\n",
    "                                  map_index(doc['answer']), #correct answer\n",
    "                                  '', #overall\n",
    "                                  doc['domain'] #domain\n",
    "                                  ])\n",
    "                elif question_type == 'multiple-selection' or question_type == 'fill-the-blank':\n",
    "                    manual_uuid.append(doc['uuid']) #they do not suppor bulk upload this type of question, we need to manually add them\n",
    "                exported_uuid.append(doc['uuid'])\n",
    "    #update this doc is exported\n",
    "    print('\",\"'.join(manual_uuid))\n",
    "    #save all questions to csv\n",
    "    try:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(file_data)\n",
    "            print(f\"Data successfully saved to '{filename}'\")\n",
    "            for _id in exported_uuid:\n",
    "                collection.update_one({'uuid': _id}, {'$set': {'exported': 1, 'filename': filename}})\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the array: {e}\")\n",
    "    \n",
    "#test|\n",
    "export_csv('aws_pmp_test_6_20250506.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
