{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pymongo\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the path to the parent directory\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import const\n",
    "#importlib.reload(const)    #if we update the file const.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "GENERATIVE_URI = os.environ['GENERATIVE_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient(os.environ['DB_URI'])\n",
    "db = db_client['db_certificates']\n",
    "collection = db['tb_psm_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a POST request\n",
    "def post_request_generative_ai(text_prompt):\n",
    "    HEADER = {'Content-Type': 'application/json'}\n",
    "    json_data = {\n",
    "        \"contents\": [\n",
    "            { \"parts\": [\n",
    "                {\"text\": text_prompt}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(GENERATIVE_URI, headers=HEADER, json=json_data)\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "       print(e)\n",
    "       return {'error': e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert questions first\n",
    "def insert_questions(json_question):\n",
    "    if 'question' in json_question:\n",
    "        existed_doc = collection.find_one({'question': json_question['question']})\n",
    "        if existed_doc == None:\n",
    "            #insert new document\n",
    "            collection.insert_one(json_question)\n",
    "            #print('Inserted new doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map A - D to 1 - 4\n",
    "def map_index(a_char):\n",
    "    if a_char == 'A':\n",
    "        return 1\n",
    "    if a_char == 'B':\n",
    "        return 2\n",
    "    if a_char == 'C':\n",
    "        return 3\n",
    "    if a_char == 'D':\n",
    "        return 4\n",
    "    if a_char == 'E':\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_candidate_content(data):\n",
    "    \"\"\"\n",
    "    Parses the content from a dictionary in the 'candidates' list.\n",
    "    Specifically looks for JSON content within the 'text' part\n",
    "    and attempts to load it.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary representing an item in the 'candidates' list.\n",
    "\n",
    "    Returns:\n",
    "        dict or str or None: If JSON content is found and successfully\n",
    "                             parsed, it returns the parsed dictionary.\n",
    "                             If no JSON is found, it returns the raw text.\n",
    "                             Returns None if the expected structure is not found.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict) or 'content' not in data or not isinstance(data['content'], dict) or 'parts' not in data['content'] or not isinstance(data['content']['parts'], list):\n",
    "        return None\n",
    "\n",
    "    for part in data['content']['parts']:\n",
    "        if isinstance(part, dict) and 'text' in part:\n",
    "            text_content = part['text'].strip()\n",
    "            # Use regex to find JSON blocks within the text\n",
    "            json_match = re.search(r'```json\\n(.*?)\\n```', text_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    return json.loads(json_match.group(1))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    return text_content  # Return the raw text in case of an error\n",
    "            elif text_content:\n",
    "                return text_content  # Return the raw text if no JSON block is found\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_questions_from_candidates(response_data):\n",
    "    \"\"\"\n",
    "    Extracts and parses the 'questions' list from the 'candidates'\n",
    "    in the given response data.\n",
    "\n",
    "    Args:\n",
    "        response_data (dict): The dictionary containing the response data.\n",
    "\n",
    "    Returns:\n",
    "        list or None: A list of question dictionaries if found and parsed,\n",
    "                     otherwise None.\n",
    "    \"\"\"\n",
    "    if not isinstance(response_data, dict) or 'candidates' not in response_data or not isinstance(response_data['candidates'], list):\n",
    "        return None\n",
    "\n",
    "    for candidate in response_data['candidates']:\n",
    "        parsed_content = parse_candidate_content(candidate)\n",
    "        if isinstance(parsed_content, dict) and 'questions' in parsed_content and isinstance(parsed_content['questions'], list):\n",
    "            return parsed_content['questions']\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example usage with your provided data:\n",
    "#response_data = {'candidates': [{'content': {'parts': [{'text': '```json\\n{\\n  \"questions\": [\\n    {\\n      \"question\": \"Your company is launching a new e-commerce platform on AWS.  The platform will handle sensitive customer data, including credit card information and personally identifiable information (PII). You need to design a secure architecture that meets PCI DSS compliance requirements.  Describe a comprehensive approach to securing the application, covering data at rest, data in transit, and access control. Consider the use of specific AWS services and explain your rationale for choosing them.  Focus on practical implementation details rather than just naming services.\",\\n      \"topics\": [\"Data Security\", \"PCI DSS Compliance\", \"IAM\", \"KMS\", \"VPC\", \"Security Groups\", \"WAF\", \"S3\", \"Encryption\"],\\n      \"difficulty\": \"Hard\"\\n    },\\n    {\\n      \"question\": \"A client has an existing on-premises application that needs to be migrated to AWS. The application interacts with a legacy database that contains highly sensitive customer records. During the migration, you must ensure that the database remains secure and complies with data sovereignty regulations for Europe (GDPR).  How would you design the migration strategy to minimize downtime and maintain security throughout the process?  Be specific about your choices of AWS services and how you will address data encryption, network security, and compliance.  Consider potential challenges and mitigation strategies.\",\\n      \"topics\": [\"Data Sovereignty\", \"GDPR\", \"Database Migration\", \"VPN\", \"Direct Connect\", \"RDS\", \"Database Encryption\", \"IAM Roles\", \"Network Security\", \"Disaster Recovery\"],\\n      \"difficulty\": \"Medium\"\\n    }\\n  ]\\n}\\n```\\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.3347730217091848}], 'usageMetadata': {'promptTokenCount': 55, 'candidatesTokenCount': 341, 'totalTokenCount': 396, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 55}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 341}]}, 'modelVersion': 'gemini-1.5-flash'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Finish loop: 0\n",
      "===== Finish loop: 1\n",
      "===== Finish loop: 2\n",
      "===== Finish loop: 3\n",
      "===== Finish loop: 4\n",
      "===== Finish loop: 5\n",
      "===== Finish loop: 6\n",
      "===== Finish loop: 7\n",
      "===== Finish loop: 8\n",
      "===== Finish loop: 9\n"
     ]
    }
   ],
   "source": [
    "#PSM I: 80 questions (70 multi choice, 5 multi select, 5 true false)\n",
    "def generate_questions():\n",
    "    context = 'PSM (Professional Scrum Master) I includes questions from the following Focus Areas as defined in the Professional Scrum Competencies: \"Understanding and Applying the Scrum Framework: Empiricism, Scrum Values, Scrum Team, Events, Artifacts, Done. Developing People and Teams: Self-Managing Teams, Facilitation, Coaching. Managing Products with Agility: Forecasting & Release Planning, Product Value, Product Backlog Management, Stakeholders & Customers.\"'\n",
    "    #multiple choice\n",
    "    #text_prompt = 'Generate 10 high-quality multiple-choice questions with answers and explanations for the PSM I examination. Each question has more than 60 words in length and should focus more on complex real-world scenarios rather than definitions. Please provide a response in a structured JSON format with the key name \"questions\", including all explanations for each answer as a JSON object. Each explanation has more than 50 words. Sample response structure should like this: { \"question\" : \"xxx\", \"options\" : { \"A\" : \"a text\", \"B\" : \"a text\", \"C\" : \"a text\", \"D\" : \"a text\"},\"answer\" : \"B\",\"explanation\" : { \"A\" : \"a text\", \"B\" : \"a text\", \"C\" : \"a text\", \"D\" : \"a text\"},\"type\" : \"multiple-choice\"}. Response should avoid error while parsing JSON format \"Error decoding JSON: Expecting property name enclosed in double quotes\".'\n",
    "    #true/false\n",
    "    #text_prompt = 'Generate 4 high-quality true-false questions (50% true, 50% false) with answers and explanations for the PSM I examination. Each question has more than 60 words in length and should focus more on complex real-world scenarios rather than definitions. Please provide a response in a structured JSON format with the key name \"questions\", including all explanations for each answer as a JSON object. Each explanation has more than 50 words. Sample response structure should like this: { \"question\" : \"xxx\", \"options\" : { \"A\" : \"True\", \"B\" : \"False\"},\"answer\" : \"A\",\"explanation\" : { \"A\" : \"a text\", \"B\" : \"a text\"},\"type\" : \"true-false\"}. Response should avoid error while parsing JSON format \"Error decoding JSON: Expecting property name enclosed in double quotes\".'\n",
    "    #multi selection\n",
    "    text_prompt = 'Generate 6 high-quality multiple-selection questions with answers and explanations for the PSM I examination. Each question has more than 60 words in length and should focus more on complex real-world scenarios rather than definitions. Please provide a response in a structured JSON format with the key name \"questions\", including all explanations for each answer as a JSON object. Each explanation has more than 50 words. Sample response structure should like this: { \"question\" : \"xxx\", \"options\" : { \"A\" : \"a text\", \"B\" : \"a text\", \"C\" : \"a text\", \"D\" : \"a text\", \"E\": \"a_text\"},\"answer\" : [],\"explanation\" : { \"A\" : \"a text\", \"B\" : \"a text\", \"C\" : \"a text\", \"D\" : \"a text\", \"E\" : \"a text\"},\"type\" : \"multiple-selection\"}. \"answer\" should have 2 to 4 correct elements.Response should avoid error while parsing JSON format \"Error decoding JSON: Expecting property name enclosed in double quotes\".'\n",
    "    #\n",
    "    raw_generated_text = post_request_generative_ai(context + text_prompt)\n",
    "\n",
    "    #print(raw_generated_text)\n",
    "    questions = extract_questions_from_candidates(raw_generated_text)\n",
    "    if questions:\n",
    "        #parse questions and answers\n",
    "        for q in questions:\n",
    "            q['exported'] = 0\n",
    "            q['uuid'] = const.generate_random_uuid()\n",
    "            #print(q)\n",
    "            insert_questions(q)\n",
    "    else:\n",
    "        print(raw_generated_text)\n",
    "        print(\"No questions found in the parsed content\")\n",
    "#test\n",
    "for i in range(10):\n",
    "    #generate_questions() #10 sentences 30 secs\n",
    "    print('===== Finish loop: ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unify fields in all documents\n",
    "def unify_fields():\n",
    "    #questionType, question_type -> type\n",
    "    # correctAnswer, correctAnswers -> answer\n",
    "    # answers -> options\n",
    "    all_docs = collection.find({'exported':0, 'type':'multiple-choice', 'explanation':None})\n",
    "    for doc in all_docs:\n",
    "        hasUpdated = False\n",
    "        update_doc = {}\n",
    "        #print(doc['uuid'])\n",
    "        # if 'type' not in doc:\n",
    "        #     if 'questionType' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = doc['questionType']\n",
    "        #     elif 'question_type' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = doc['question_type']\n",
    "        #     else:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['type'] = 'multiple-choice'\n",
    "        # if 'answer' not in doc:\n",
    "        #     if 'correctAnswer' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['answer'] = doc['correctAnswer']\n",
    "        #     elif 'correctAnswers' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['answer'] = doc['correctAnswers']\n",
    "        # if 'options' not in doc:\n",
    "        #     if 'answers' in doc:\n",
    "        #         hasUpdated = True\n",
    "        #         update_doc['options'] = doc['answers']\n",
    "\n",
    "        #if hasUpdated:\n",
    "        #print('a')\n",
    "        #collection.update_one({'uuid': doc['uuid']}, {'$set': {'explanation': doc['explanations']}})\n",
    "    #update 2\n",
    "    # all_docs = collection.find({'filename': 'aws_pmp_test_6_20250506.csv'})\n",
    "    # for doc in all_docs:\n",
    "    #     collection.update_one({'uuid': doc['uuid']}, {'$set': {'exported': 0, 'filename': ''}})\n",
    "\n",
    "#test\n",
    "#unify_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40b715ad-4ec8-47d9-87c8-430bcbbc1e65\",\"cdfc62cc-c8fc-4ca4-8a1f-c24f89f6246f\",\"d09fdd5e-02d7-46ae-9d8f-c3d40439094f\",\"dc42598c-059f-43ce-b970-d1c03ada98f0\n",
      "Data successfully saved to 'aws_psm_I_test_6_20250506.csv'\n"
     ]
    }
   ],
   "source": [
    "#Question,Question Type,Answer Option 1,Explanation 1,Answer Option 2,Explanation 2,Answer Option 3,Explanation 3,Answer Option 4,Explanation 4,Answer Option 5,Explanation 5,Answer Option 6,Explanation 6,Correct Answers,Overall Explanation,Domain\n",
    "def export_csv(path, filename):\n",
    "    #get questions that not exported yet. Note that: each part must follow by domain percents\n",
    "    file_data = []\n",
    "    #append header line (both multi-choice and multi-selection)\n",
    "    file_data.append(['Question','Question Type','Answer Option 1','Explanation 1','Answer Option 2','Explanation 2','Answer Option 3','Explanation 3','Answer Option 4','Explanation 4','Answer Option 5','Explanation 5','Answer Option 6','Explanation 6','Correct Answers','Overall Explanation','Domain'])\n",
    "    exported_uuid = []\n",
    "    manual_uuid = []\n",
    "    #1. export multiple-choice first\n",
    "    pipeline = [\n",
    "                {\"$match\": {'exported': 0, 'type': 'multiple-choice'}},\n",
    "                {\"$sample\": {\"size\": 72}}\n",
    "            ]\n",
    "    random_documents = list(collection.aggregate(pipeline))\n",
    "    for doc in random_documents:\n",
    "        file_data.append([doc['question'].replace('  ', ' ').replace('\\n', ''), 'multiple-choice', \n",
    "                                  doc['options']['A'], doc['explanation']['A'].replace('  ', ' ').replace('\\n', ''),     #A\n",
    "                                  doc['options']['B'], doc['explanation']['B'].replace('  ', ' ').replace('\\n', ''),     #B\n",
    "                                  doc['options']['C'], doc['explanation']['C'].replace('  ', ' ').replace('\\n', ''),     #C\n",
    "                                  doc['options']['D'], doc['explanation']['D'].replace('  ', ' ').replace('\\n', ''),     #D\n",
    "                                  '', '',   #E\n",
    "                                  '', '',   #6\n",
    "                                  map_index(doc['answer']), #correct answer\n",
    "                                  '', #overall\n",
    "                                  '' #domain\n",
    "                                  ])\n",
    "        exported_uuid.append(doc['uuid'])\n",
    "    #2. true false questions\n",
    "    pipeline = [\n",
    "                {\"$match\": {'exported': 0, 'type': 'true-false'}},\n",
    "                {\"$sample\": {\"size\": 4}}\n",
    "            ]\n",
    "    random_documents = list(collection.aggregate(pipeline))\n",
    "    for doc in random_documents:\n",
    "        file_data.append([doc['question'].replace('  ', ' ').replace('\\n', ''), 'multiple-choice', \n",
    "                                  doc['options']['A'], doc['explanation']['A'].replace('  ', ' ').replace('\\n', ''),     #A\n",
    "                                  doc['options']['B'], doc['explanation']['B'].replace('  ', ' ').replace('\\n', ''),     #B\n",
    "                                  '', '',     #C\n",
    "                                  '', '',     #D\n",
    "                                  '', '',   #E\n",
    "                                  '', '',   #6\n",
    "                                  map_index(doc['answer']), #correct answer\n",
    "                                  '', #overall\n",
    "                                  '' #domain\n",
    "                                  ])\n",
    "        exported_uuid.append(doc['uuid'])\n",
    "    #3. multi selection\n",
    "    pipeline = [\n",
    "                {\"$match\": {'exported': 0, 'type': 'multiple-selection'}},\n",
    "                {\"$sample\": {\"size\": 4}}\n",
    "            ]\n",
    "    random_documents = list(collection.aggregate(pipeline))\n",
    "    for doc in random_documents:\n",
    "        exported_uuid.append(doc['uuid'])\n",
    "        manual_uuid.append(doc['uuid']) #they do not suppor bulk upload this type of question, we need to manually add them\n",
    "    #\n",
    "    print('\",\"'.join(manual_uuid))\n",
    "    #save all questions to csv\n",
    "    try:\n",
    "        with open(path + filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(file_data)\n",
    "            print(f\"Data successfully saved to '{filename}'\")\n",
    "            for _id in exported_uuid:\n",
    "                collection.update_one({'uuid': _id}, {'$set': {'exported': 1, 'filename': filename}})\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the array: {e}\")\n",
    "    \n",
    "#test|\n",
    "export_csv('./psm_1_data/', 'aws_psm_I_test_6_20250506.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
