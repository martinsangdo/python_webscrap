{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate questions for AWS SA exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pymongo\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the path to the parent directory\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import const\n",
    "#importlib.reload(const)    #if we update the file const.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "GENERATIVE_URI = os.environ['GENERATIVE_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient(os.environ['DB_URI'])\n",
    "db = db_client['db_certificates']\n",
    "collection = db['tb_aws_sa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_SERVICES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_QUESTIONS = 65\n",
    "DOMAINS = [\n",
    "    {\n",
    "        \"name\": \"Secure\",\n",
    "        \"percent\": 30,\n",
    "        \"num\": 19\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Resilient\",\n",
    "        \"percent\": 26,\n",
    "        \"num\": 16\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High-Performing\",\n",
    "        \"percent\": 24,\n",
    "        \"num\": 15\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Cost-Optimized\",\n",
    "        \"percent\": 20,\n",
    "        \"num\": 15 \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determin how many questions in each domain\n",
    "def get_questions_each_domain():\n",
    "    for domain in DOMAINS:\n",
    "        no_quest = int(domain['percent'] * TOTAL_QUESTIONS / 100)\n",
    "        print(no_quest)\n",
    "#test\n",
    "#get_questions_each_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a POST request\n",
    "def post_request_generative_ai(text_prompt):\n",
    "    HEADER = {'Content-Type': 'application/json'}\n",
    "    json_data = {\n",
    "        \"contents\": [\n",
    "            { \"parts\": [\n",
    "                #{\"text\": text_prompt + \" Please provide a response in a structured JSON format, including all explanations for each option as JSON format. Each explanation should have 40 to 60 words.\"}]\n",
    "                {\"text\": text_prompt + \" Please provide a plain string response.\"}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(GENERATIVE_URI, headers=HEADER, json=json_data)\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "       print(e)\n",
    "       return {'error': e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert questions first\n",
    "def insert_questions(json_question):\n",
    "    existed_doc = collection.find_one({'question': json_question['question']})\n",
    "    if existed_doc == None:\n",
    "        #insert new document\n",
    "        collection.insert_one(json_question)\n",
    "        #print('Inserted new doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_candidate_content(data):\n",
    "    \"\"\"\n",
    "    Parses the content from a dictionary in the 'candidates' list.\n",
    "    Specifically looks for JSON content within the 'text' part\n",
    "    and attempts to load it.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary representing an item in the 'candidates' list.\n",
    "\n",
    "    Returns:\n",
    "        dict or str or None: If JSON content is found and successfully\n",
    "                             parsed, it returns the parsed dictionary.\n",
    "                             If no JSON is found, it returns the raw text.\n",
    "                             Returns None if the expected structure is not found.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict) or 'content' not in data or not isinstance(data['content'], dict) or 'parts' not in data['content'] or not isinstance(data['content']['parts'], list):\n",
    "        return None\n",
    "\n",
    "    for part in data['content']['parts']:\n",
    "        if isinstance(part, dict) and 'text' in part:\n",
    "            text_content = part['text'].strip()\n",
    "            # Use regex to find JSON blocks within the text\n",
    "            json_match = re.search(r'```json\\n(.*?)\\n```', text_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    return json.loads(json_match.group(1))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    return text_content  # Return the raw text in case of an error\n",
    "            elif text_content:\n",
    "                return text_content  # Return the raw text if no JSON block is found\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_questions_from_candidates(response_data):\n",
    "    \"\"\"\n",
    "    Extracts and parses the 'questions' list from the 'candidates'\n",
    "    in the given response data.\n",
    "\n",
    "    Args:\n",
    "        response_data (dict): The dictionary containing the response data.\n",
    "\n",
    "    Returns:\n",
    "        list or None: A list of question dictionaries if found and parsed,\n",
    "                     otherwise None.\n",
    "    \"\"\"\n",
    "    if not isinstance(response_data, dict) or 'candidates' not in response_data or not isinstance(response_data['candidates'], list):\n",
    "        return None\n",
    "\n",
    "    for candidate in response_data['candidates']:\n",
    "        parsed_content = parse_candidate_content(candidate)\n",
    "        if isinstance(parsed_content, dict) and 'questions' in parsed_content and isinstance(parsed_content['questions'], list):\n",
    "            return parsed_content['questions']\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example usage with your provided data:\n",
    "#response_data = {'candidates': [{'content': {'parts': [{'text': '```json\\n{\\n  \"questions\": [\\n    {\\n      \"question\": \"Your company is launching a new e-commerce platform on AWS.  The platform will handle sensitive customer data, including credit card information and personally identifiable information (PII). You need to design a secure architecture that meets PCI DSS compliance requirements.  Describe a comprehensive approach to securing the application, covering data at rest, data in transit, and access control. Consider the use of specific AWS services and explain your rationale for choosing them.  Focus on practical implementation details rather than just naming services.\",\\n      \"topics\": [\"Data Security\", \"PCI DSS Compliance\", \"IAM\", \"KMS\", \"VPC\", \"Security Groups\", \"WAF\", \"S3\", \"Encryption\"],\\n      \"difficulty\": \"Hard\"\\n    },\\n    {\\n      \"question\": \"A client has an existing on-premises application that needs to be migrated to AWS. The application interacts with a legacy database that contains highly sensitive customer records. During the migration, you must ensure that the database remains secure and complies with data sovereignty regulations for Europe (GDPR).  How would you design the migration strategy to minimize downtime and maintain security throughout the process?  Be specific about your choices of AWS services and how you will address data encryption, network security, and compliance.  Consider potential challenges and mitigation strategies.\",\\n      \"topics\": [\"Data Sovereignty\", \"GDPR\", \"Database Migration\", \"VPN\", \"Direct Connect\", \"RDS\", \"Database Encryption\", \"IAM Roles\", \"Network Security\", \"Disaster Recovery\"],\\n      \"difficulty\": \"Medium\"\\n    }\\n  ]\\n}\\n```\\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.3347730217091848}], 'usageMetadata': {'promptTokenCount': 55, 'candidatesTokenCount': 341, 'totalTokenCount': 396, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 55}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 341}]}, 'modelVersion': 'gemini-1.5-flash'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_of_questions():\n",
    "    no_of_questions = 0\n",
    "    for domain in DOMAINS:\n",
    "        #domain['num'] = 1 #testing\n",
    "        text_prompt = \"Generate \"+str(domain['num'])+\" multiple-choice questions for me to practice AWS certified solution architect - associate exam in the domain: Design \"+domain['name']+\" architecture. I want questions that focus more on real-world scenarios and problem-solving rather than just definitions of services.\"\n",
    "        raw_generated_text = post_request_generative_ai(text_prompt)\n",
    "        \n",
    "        questions = extract_questions_from_candidates(raw_generated_text)\n",
    "        if questions:\n",
    "            #parse questions and answers\n",
    "            for q in questions:\n",
    "                q['domain'] = domain['name']\n",
    "                q['exported'] = 0\n",
    "                q['uuid'] = const.generate_random_uuid()\n",
    "                #print(q)\n",
    "                insert_questions(q)\n",
    "                no_of_questions += 1\n",
    "        else:\n",
    "            print(raw_generated_text)\n",
    "            print(\"No questions found in the parsed content: \" + domain['name'])\n",
    "        print(domain['name'] + ': ' + str(no_of_questions))\n",
    "#test\n",
    "#for i in range(4):\n",
    "    #generate_list_of_questions()    #approx. 1m22s for 1 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map A - D to 1 - 4\n",
    "def map_index(a_char):\n",
    "    if a_char == 'A':\n",
    "        return 1\n",
    "    if a_char == 'B':\n",
    "        return 2\n",
    "    if a_char == 'C':\n",
    "        return 3\n",
    "    if a_char == 'D':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to 'aws_sa_test_3_20250504.csv'\n",
      "Data successfully saved to 'aws_sa_test_4_20250504.csv'\n",
      "Data successfully saved to 'aws_sa_test_5_20250504.csv'\n",
      "Data successfully saved to 'aws_sa_test_6_20250504.csv'\n"
     ]
    }
   ],
   "source": [
    "#export to the CSV file, each file has 65 questions\n",
    "#Question,Question Type,Answer Option 1,Explanation 1,Answer Option 2,Explanation 2,Answer Option 3,Explanation 3,Answer Option 4,Explanation 4,Answer Option 5,Explanation 5,Answer Option 6,Explanation 6,Correct Answers,Overall Explanation,Domain\n",
    "def export_csv(filename):\n",
    "    #get questions that not exported yet. Note that: each part must follow by domain percents\n",
    "    file_data = []\n",
    "    #append header line\n",
    "    file_data.append(['Question','Question Type','Answer Option 1','Explanation 1','Answer Option 2','Explanation 2','Answer Option 3','Explanation 3','Answer Option 4','Explanation 4','Answer Option 5','Explanation 5','Answer Option 6','Explanation 6','Correct Answers','Overall Explanation','Domain'])\n",
    "        \n",
    "    for domain in DOMAINS:\n",
    "        #todo: get random questions\n",
    "        pipeline = [\n",
    "            {\"$match\": {'exported': 0, 'domain': domain['name']}},\n",
    "            {\"$sample\": {\"size\": domain['num']}}\n",
    "        ]\n",
    "        random_documents = list(collection.aggregate(pipeline))\n",
    "        #print(random_documents)\n",
    "        for doc in random_documents:\n",
    "            file_data.append([doc['question'].replace('  ', ' ').replace('\\n', ''), 'multiple-choice', \n",
    "                              doc['options']['A'], doc['explanation']['A'],     #A\n",
    "                              doc['options']['B'], doc['explanation']['B'],     #B\n",
    "                              doc['options']['C'], doc['explanation']['C'],     #C\n",
    "                              doc['options']['D'], doc['explanation']['D'],     #D\n",
    "                              '', '',   #5\n",
    "                              '', '',   #6\n",
    "                              map_index(doc['answer']), #correct answer\n",
    "                              '', #overall\n",
    "                              doc['domain'] #domain\n",
    "                              ])\n",
    "            #update this doc is exported\n",
    "            collection.update_one({'uuid': doc['uuid']}, {'$set': {'exported': 1, 'filename': filename}})\n",
    "    #save all questions to csv\n",
    "    try:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(file_data)\n",
    "        print(f\"Data successfully saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the array: {e}\")\n",
    "    #\n",
    "#test\n",
    "#for i in range(2,6):\n",
    "    #export_csv('aws_sa_test_'+str(i+1)+'_20250504.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset doc from file #3\n",
    "def reset_data():\n",
    "    docs = collection.find({'exported': 1, 'filename': {'$in': ['aws_sa_test_3_20250504.csv','aws_sa_test_4_20250504.csv','aws_sa_test_5_20250504.csv','aws_sa_test_6_20250504.csv']}})\n",
    "    i = 0\n",
    "    for doc in docs:\n",
    "        if i < 600:\n",
    "            has_error = False\n",
    "            #for key in doc['explanation'].keys():\n",
    "                    #revise the text\n",
    "                    #result = post_request_generative_ai('Revise this sentence to 40 to 60 words: ' + doc['explanation'][key])\n",
    "                    #print(result)\n",
    "                    # try:\n",
    "                    #     doc['explanation'][key] = result['candidates'][0]['content']['parts'][0]['text'].replace('  ', ' ').replace('\\n', '')\n",
    "                    # except:\n",
    "                    #     #cannot revise this explanation\n",
    "                    #     has_error = True\n",
    "                    #     break\n",
    "            if not has_error:\n",
    "                collection.update_one({'uuid': doc['uuid']}, {'$set': {'exported': 0, 'filename': ''}})\n",
    "                print(str(i) + ': ' + doc['uuid'])  #revised doc\n",
    "        else:\n",
    "             break\n",
    "        i += 1\n",
    "        \n",
    "#test\n",
    "#reset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
