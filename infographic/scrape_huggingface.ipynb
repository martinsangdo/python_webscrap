{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape models info from Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- List of categories\n",
    "- List of models inside each category\n",
    "- Model:\n",
    "    + Name\n",
    "    + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define list of tasks\n",
    "categories = [] #'Multimodal', 'Computer Vision', 'Natural Language Processing', 'Audio', 'Tabular', 'Reinforcement Learning'\n",
    "cat_map = {}    #key: category, value: list of tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_query(get_url):\n",
    "    #print(get_url)\n",
    "    try:\n",
    "        r = requests.get(get_url)\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "       print(e)\n",
    "       return {'error': e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find task statistics\n",
    "def find_task_details(tag):\n",
    "    simple_details = {}\n",
    "    details = custom_query('https://huggingface.co/models-json?sort=downloads&withCount=true&pipeline_tag=' + tag)\n",
    "    if 'error' in details:\n",
    "        return {}   #error\n",
    "    #extract basic info\n",
    "    simple_details['numTotalItems'] = details['numTotalItems']\n",
    "    if 'models' in details:\n",
    "        model_details = []\n",
    "        for model in details['models']:\n",
    "            model_details.append({\n",
    "                'id': model['id'],\n",
    "                'downloads': model['downloads']\n",
    "            })\n",
    "        simple_details['models'] = model_details\n",
    "    return simple_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape and export to json file\n",
    "def scrape_huggingface():\n",
    "    list_url = 'https://huggingface.co/models?sort=trending'\n",
    "    response = requests.get(list_url)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    items = soup.find_all('div', attrs={'class': 'mb-3'})\n",
    "    index = 0\n",
    "    for item in items:\n",
    "        a_tags = item.find_all('a', attrs={'class': 'mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg'})\n",
    "        if a_tags != None and len(a_tags) > 0:\n",
    "            cat_tag = item.find('div', attrs={'class': 'mb-3 text-sm font-medium text-gray-500'})\n",
    "            cat_name = cat_tag.text.strip().replace('\\n', \"\").replace('\\t', \"\")\n",
    "            categories.append(cat_name)\n",
    "            task_list = []\n",
    "            for a_tag in a_tags:\n",
    "                # if index > 0:\n",
    "                #     break\n",
    "                tag_name = a_tag['href'].replace('/models?pipeline_tag=', '')\n",
    "                task_details = find_task_details(tag_name)\n",
    "                task_list.append({\n",
    "                    'tag': tag_name,\n",
    "                    'name': a_tag.find('span').text,\n",
    "                    'task_details': task_details\n",
    "                })\n",
    "                index += 1\n",
    "            cat_map[cat_name+''] = task_list\n",
    "            # if index > 0:\n",
    "            #     break\n",
    "\n",
    "    #done (1m 40s)\n",
    "    #print(cat_map)\n",
    "    with open('huggingface_modellist.json', 'w') as f:\n",
    "        f.write(str(cat_map).replace(\"'\", '\"'))\n",
    "#test\n",
    "scrape_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filepath):\n",
    "    with open('huggingface_modellist.json', 'r') as file:\n",
    "      data = json.load(file)\n",
    "      return data\n",
    "#\n",
    "data = read_json_file('huggingface_modellist.json')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(arr):\n",
    "    return sorted(arr, key=lambda item: item['total'])  #default ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal ==========\n",
      "1. Image Text to Text 7666\n",
      "2. Any to Any 6669\n",
      "3. Visual Question Answering 473\n",
      "4. Document Question Answering 221\n",
      "5. Video Text to Text 90\n",
      "6. Audio Text to Text 56\n",
      "7. Visual Document Retrieval 38\n",
      "Computer Vision ==========\n",
      "1. Text to Image 66719\n",
      "2. Image Classification 16266\n",
      "3. Object Detection 3169\n",
      "4. Unconditional Image Generation 1890\n",
      "5. Video Classification 1424\n",
      "6. Image Segmentation 1253\n",
      "7. Image to Image 962\n",
      "8. Zero Shot Image Classification 889\n",
      "9. Image to Text 776\n",
      "10. Image Feature Extraction 597\n",
      "11. Text to Video 416\n",
      "12. Image to 3D 197\n",
      "13. Depth Estimation 188\n",
      "14. Mask Generation 184\n",
      "15. Image to Video 135\n",
      "16. Text to 3D 56\n",
      "17. Keypoint Detection 56\n",
      "18. Zero Shot Object Detection 48\n",
      "Natural Language Processing ==========\n",
      "1. Text Generation 199746\n",
      "2. Text Classification 88572\n",
      "3. Text2Text Generation 37097\n",
      "4. Token Classification 21670\n",
      "5. Fill Mask 14192\n",
      "6. Question Answering 13061\n",
      "7. Feature Extraction 11834\n",
      "8. Sentence Similarity 9354\n",
      "9. Translation 5446\n",
      "10. Summarization 2253\n",
      "11. Zero Shot Classification 381\n",
      "12. Table Question Answering 145\n",
      "13. Text Ranking 6\n",
      "Audio ==========\n",
      "1. Automatic Speech Recognition 22941\n",
      "2. Audio to Audio 3906\n",
      "3. Audio Classification 3075\n",
      "4. Text to Speech 2701\n",
      "5. Text to Audio 1949\n",
      "6. Voice Activity Detection 52\n",
      "Tabular ==========\n",
      "1. Tabular Classification 286\n",
      "2. Tabular Regression 158\n",
      "3. Time Series Forecasting 100\n",
      "Reinforcement Learning ==========\n",
      "1. Reinforcement Learning 56204\n",
      "2. Robotics 456\n",
      "Other ==========\n",
      "1. Graph Machine Learning 60\n",
      "----------\n",
      "606083\n",
      "{'Multimodal': 15213, 'Computer Vision': 95225, 'Natural Language Processing': 403757, 'Audio': 34624, 'Tabular': 544, 'Reinforcement Learning': 56660, 'Other': 60}\n",
      "Multimodal: 2.51\n",
      "Computer Vision: 15.71\n",
      "Natural Language Processing: 66.62\n",
      "Audio: 5.71\n",
      "Tabular: 0.09\n",
      "Reinforcement Learning: 9.35\n",
      "Other: 0.01\n"
     ]
    }
   ],
   "source": [
    "#show data\n",
    "def show_data():\n",
    "    #find percentage of each category\n",
    "    total_models = 0\n",
    "    total_models_map = {} #key: cat, value: total models\n",
    "    for cat in data.keys():\n",
    "        print(cat + ' ==========')\n",
    "        sub_cats = data[cat]\n",
    "        total_models_map[cat] = 0\n",
    "        index = 1\n",
    "        sorted_sub_cats = sorted(sub_cats, key=lambda item: item['task_details']['numTotalItems'], reverse=True)\n",
    "        for sub_cat in sorted_sub_cats:\n",
    "            total_models += sub_cat['task_details']['numTotalItems']\n",
    "            total_models_map[cat] += sub_cat['task_details']['numTotalItems']\n",
    "            #print sub model categories\n",
    "            print(str(index) + '. ' + sub_cat['name'].replace('-', ' ') + ' ' + str(sub_cat['task_details']['numTotalItems']))\n",
    "            index += 1\n",
    "    #print percentage of categories\n",
    "    print('----------')\n",
    "    print(str(total_models))\n",
    "    print(total_models_map)\n",
    "    for cat in total_models_map:\n",
    "         print(cat + ': ' + str(round((total_models_map[cat] / total_models) * 100, 2)))\n",
    "\n",
    "\n",
    "#test\n",
    "show_data()\n",
    "#arrTotal = [7, 18, 13, 6, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
